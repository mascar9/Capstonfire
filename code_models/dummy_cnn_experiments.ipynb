{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "from torchmetrics import Recall, Precision, F1Score\n",
    "from torchmetrics.classification import BinaryRecall, BinaryPrecision, BinaryF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\johnn\\\\Desktop\\\\Repos\\\\Capstonfire\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook (\".\\dummy_cnn.ipynb\"), we created and trained our first model using only images of the FIRE dataset. This model will be our baseline model from which we will compare future models in regards to their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first experiment, let's try and use the Adam optimizer and see how if the model improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to streamline new experiments, we created a Python module where we added the FireDataset class, the SimpleCNN class with our neural network architecture, the training cycle, and the metrics calculations. This module is in \".\\capstonfire_utils.py\" file. We also passed the dataset spliter into dataloaders and the accuracy and loss plot functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capstonfire_utils import FireDataset, SimpleCNN, split_dataset_into_dataloaders, train_model, calculate_metrics, plot_accuracy, plot_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dummy_cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FireDataset(os.path.join(base_path, \"FIRE Dataset\"), transforms=transform)\n",
    "\n",
    "train_loader, val_loader, test_loader = split_dataset_into_dataloaders(dataset, 50, 0.7, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0003, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, criterion, optimizer, base_path, model_name, 20, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(base_path, \"test dataset\")\n",
    "\n",
    "custom_test_loader = DataLoader(FireDataset(test_path, transforms=transform), batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d5807da3424dc5b8cae78b7409e92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on the test set: 0.68\n",
      "Precision on the test set: 0.68\n",
      "F1 Score on the test set: 0.68\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(model, custom_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done. For now, let's test the training with a better optimizer. We will use Adam for this. Since Adam trains far faster than simple gradient descent, we will train with only 5 epochs, to avoid overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model_name = \"adam_dummy_cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_model = SimpleCNN()\n",
    "adam_optimizer = optim.Adam(adam_model.parameters(), lr=0.0003)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba335f28ef9d45da923009834405ae9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 0.5423, Train Accuracy: 0.7329, Validation Loss: 0.4512, Validation Accuracy: 0.7250\n",
      "Epoch [2/5], Train Loss: 0.3503, Train Accuracy: 0.7957, Validation Loss: 0.3399, Validation Accuracy: 0.9000\n",
      "Epoch [3/5], Train Loss: 0.2662, Train Accuracy: 0.8943, Validation Loss: 0.2848, Validation Accuracy: 0.9200\n",
      "Epoch [4/5], Train Loss: 0.2441, Train Accuracy: 0.9257, Validation Loss: 0.3219, Validation Accuracy: 0.8900\n",
      "Epoch [5/5], Train Loss: 0.2193, Train Accuracy: 0.9457, Validation Loss: 0.2676, Validation Accuracy: 0.9350\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "adam_history = train_model(adam_model, criterion, adam_optimizer, base_path, adam_model_name, 5, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf5f00f549f487880f6f860e8e11e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on the test set: 0.63\n",
      "Precision on the test set: 0.63\n",
      "F1 Score on the test set: 0.63\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(adam_model, custom_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it got worse. The reduced epoch number might have made a large effect. Let's up them to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28064d656c4457fbd4a83f6638fcab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.3517, Train Accuracy: 0.8071, Validation Loss: 0.2805, Validation Accuracy: 0.9150\n",
      "Epoch [2/10], Train Loss: 0.1786, Train Accuracy: 0.9286, Validation Loss: 0.2986, Validation Accuracy: 0.8500\n",
      "Epoch [3/10], Train Loss: 0.1550, Train Accuracy: 0.9329, Validation Loss: 0.3035, Validation Accuracy: 0.8450\n",
      "Epoch [4/10], Train Loss: 0.1333, Train Accuracy: 0.9371, Validation Loss: 0.1731, Validation Accuracy: 0.9350\n",
      "Epoch [5/10], Train Loss: 0.0938, Train Accuracy: 0.9543, Validation Loss: 0.1612, Validation Accuracy: 0.9450\n",
      "Epoch [6/10], Train Loss: 0.0664, Train Accuracy: 0.9771, Validation Loss: 0.1594, Validation Accuracy: 0.9400\n",
      "Epoch [7/10], Train Loss: 0.0607, Train Accuracy: 0.9771, Validation Loss: 0.1538, Validation Accuracy: 0.9550\n",
      "Epoch [8/10], Train Loss: 0.0546, Train Accuracy: 0.9800, Validation Loss: 0.1511, Validation Accuracy: 0.9450\n",
      "Epoch [9/10], Train Loss: 0.0530, Train Accuracy: 0.9771, Validation Loss: 0.1468, Validation Accuracy: 0.9550\n",
      "Epoch [10/10], Train Loss: 0.0532, Train Accuracy: 0.9800, Validation Loss: 0.1854, Validation Accuracy: 0.9500\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "adam_model_name = \"adam_dummy_cnn_10\"\n",
    "adam_model = SimpleCNN()\n",
    "adam_optimizer = optim.Adam(adam_model.parameters(), lr=0.0003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "adam_history = train_model(adam_model, criterion, adam_optimizer, base_path, adam_model_name, 10, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ade80445f44ebb80a704d08599fd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on the test set: 0.68\n",
      "Precision on the test set: 0.68\n",
      "F1 Score on the test set: 0.68\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(adam_model, custom_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, looks like the problem is the lack of epochs. Let's try next with 20 then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1234b0761464acf94fc23ef58199066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.4167, Train Accuracy: 0.7929, Validation Loss: 0.3122, Validation Accuracy: 0.9100\n",
      "Epoch [2/20], Train Loss: 0.2228, Train Accuracy: 0.9100, Validation Loss: 0.2749, Validation Accuracy: 0.9100\n",
      "Epoch [3/20], Train Loss: 0.1522, Train Accuracy: 0.9400, Validation Loss: 0.2552, Validation Accuracy: 0.9150\n",
      "Epoch [4/20], Train Loss: 0.1319, Train Accuracy: 0.9471, Validation Loss: 0.2128, Validation Accuracy: 0.9300\n",
      "Epoch [5/20], Train Loss: 0.1288, Train Accuracy: 0.9443, Validation Loss: 0.1478, Validation Accuracy: 0.9350\n",
      "Epoch [6/20], Train Loss: 0.0889, Train Accuracy: 0.9686, Validation Loss: 0.1481, Validation Accuracy: 0.9500\n",
      "Epoch [7/20], Train Loss: 0.0840, Train Accuracy: 0.9671, Validation Loss: 0.1470, Validation Accuracy: 0.9500\n",
      "Epoch [8/20], Train Loss: 0.0730, Train Accuracy: 0.9757, Validation Loss: 0.2117, Validation Accuracy: 0.9200\n",
      "Epoch [9/20], Train Loss: 0.0757, Train Accuracy: 0.9714, Validation Loss: 0.1537, Validation Accuracy: 0.9450\n",
      "Epoch [10/20], Train Loss: 0.0631, Train Accuracy: 0.9771, Validation Loss: 0.1408, Validation Accuracy: 0.9500\n",
      "Epoch [11/20], Train Loss: 0.0488, Train Accuracy: 0.9843, Validation Loss: 0.1336, Validation Accuracy: 0.9600\n",
      "Epoch [12/20], Train Loss: 0.0445, Train Accuracy: 0.9857, Validation Loss: 0.1372, Validation Accuracy: 0.9600\n",
      "Epoch [13/20], Train Loss: 0.0343, Train Accuracy: 0.9886, Validation Loss: 0.1398, Validation Accuracy: 0.9500\n",
      "Epoch [14/20], Train Loss: 0.0367, Train Accuracy: 0.9857, Validation Loss: 0.1356, Validation Accuracy: 0.9600\n",
      "Epoch [15/20], Train Loss: 0.0293, Train Accuracy: 0.9929, Validation Loss: 0.1421, Validation Accuracy: 0.9550\n",
      "Epoch [16/20], Train Loss: 0.0334, Train Accuracy: 0.9900, Validation Loss: 0.1675, Validation Accuracy: 0.9500\n",
      "Epoch [17/20], Train Loss: 0.0306, Train Accuracy: 0.9900, Validation Loss: 0.1659, Validation Accuracy: 0.9500\n",
      "Epoch [18/20], Train Loss: 0.0211, Train Accuracy: 0.9943, Validation Loss: 0.1537, Validation Accuracy: 0.9450\n",
      "Epoch [19/20], Train Loss: 0.0169, Train Accuracy: 0.9957, Validation Loss: 0.1744, Validation Accuracy: 0.9450\n",
      "Epoch [20/20], Train Loss: 0.0144, Train Accuracy: 0.9971, Validation Loss: 0.1617, Validation Accuracy: 0.9550\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "adam_model_name = \"adam_dummy_cnn_20\"\n",
    "adam_model = SimpleCNN()\n",
    "adam_optimizer = optim.Adam(adam_model.parameters(), lr=0.0003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "adam_history = train_model(adam_model, criterion, adam_optimizer, base_path, adam_model_name, 20, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02053135c65648df8e891be492013e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on the test set: 0.75\n",
      "Precision on the test set: 0.75\n",
      "F1 Score on the test set: 0.75\n",
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ede71b28e5549e189f382c3eecd54c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on the test set: 0.68\n",
      "Precision on the test set: 0.68\n",
      "F1 Score on the test set: 0.68\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(adam_model, custom_test_loader)\n",
    "calculate_metrics(model, custom_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, same number of epochs and the Adam model is worse at predicting. Looks like it actually is overfitted. Perhaps the loss function profile is too simple to be using stochastic methods and Stochastic Gradient Descent is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like SDG is preferable over Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test with resized images, check if anything is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_fire_dataset = FireDataset(os.path.join(base_path, \"fire_dataset\"), transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_train_loader, resized_val_loader, resized_test_loader = split_dataset_into_dataloaders(resized_fire_dataset, 50, 0.7, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_model_name = \"resized_dummy_cnn\"\n",
    "resized_model = SimpleCNN()\n",
    "optimizer = optim.SGD(resized_model.parameters(), lr=0.0003, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e1c75c278a4a779e3116d98dff4e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.6936, Train Accuracy: 0.4929, Validation Loss: 0.5983, Validation Accuracy: 0.7500\n",
      "Epoch [2/20], Train Loss: 0.5903, Train Accuracy: 0.7457, Validation Loss: 0.5779, Validation Accuracy: 0.7500\n",
      "Epoch [3/20], Train Loss: 0.5635, Train Accuracy: 0.7457, Validation Loss: 0.5553, Validation Accuracy: 0.7500\n",
      "Epoch [4/20], Train Loss: 0.5462, Train Accuracy: 0.7457, Validation Loss: 0.5386, Validation Accuracy: 0.7500\n",
      "Epoch [5/20], Train Loss: 0.5286, Train Accuracy: 0.7457, Validation Loss: 0.5206, Validation Accuracy: 0.7500\n",
      "Epoch [6/20], Train Loss: 0.5094, Train Accuracy: 0.7457, Validation Loss: 0.5004, Validation Accuracy: 0.7500\n",
      "Epoch [7/20], Train Loss: 0.4862, Train Accuracy: 0.7457, Validation Loss: 0.4776, Validation Accuracy: 0.7500\n",
      "Epoch [8/20], Train Loss: 0.4630, Train Accuracy: 0.7457, Validation Loss: 0.4505, Validation Accuracy: 0.7500\n",
      "Epoch [9/20], Train Loss: 0.4331, Train Accuracy: 0.7457, Validation Loss: 0.4253, Validation Accuracy: 0.7550\n",
      "Epoch [10/20], Train Loss: 0.4078, Train Accuracy: 0.7657, Validation Loss: 0.3963, Validation Accuracy: 0.7800\n",
      "Epoch [11/20], Train Loss: 0.3798, Train Accuracy: 0.7786, Validation Loss: 0.3735, Validation Accuracy: 0.7850\n",
      "Epoch [12/20], Train Loss: 0.3579, Train Accuracy: 0.8129, Validation Loss: 0.3525, Validation Accuracy: 0.8450\n",
      "Epoch [13/20], Train Loss: 0.3390, Train Accuracy: 0.8314, Validation Loss: 0.3347, Validation Accuracy: 0.8650\n",
      "Epoch [14/20], Train Loss: 0.3248, Train Accuracy: 0.8529, Validation Loss: 0.3219, Validation Accuracy: 0.8800\n",
      "Epoch [15/20], Train Loss: 0.3106, Train Accuracy: 0.8600, Validation Loss: 0.3108, Validation Accuracy: 0.8900\n",
      "Epoch [16/20], Train Loss: 0.2981, Train Accuracy: 0.8786, Validation Loss: 0.2989, Validation Accuracy: 0.9000\n",
      "Epoch [17/20], Train Loss: 0.2852, Train Accuracy: 0.8914, Validation Loss: 0.3057, Validation Accuracy: 0.8650\n",
      "Epoch [18/20], Train Loss: 0.2758, Train Accuracy: 0.8986, Validation Loss: 0.2823, Validation Accuracy: 0.9150\n",
      "Epoch [19/20], Train Loss: 0.2651, Train Accuracy: 0.9100, Validation Loss: 0.2763, Validation Accuracy: 0.9200\n",
      "Epoch [20/20], Train Loss: 0.2618, Train Accuracy: 0.9243, Validation Loss: 0.2708, Validation Accuracy: 0.9150\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "resize_history = train_model(resized_model, criterion, optimizer, base_path, resized_model_name, 20, resized_train_loader, resized_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e16e16a60a1473b825aa6656f03607e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on the test set: 0.63\n",
      "Precision on the test set: 0.63\n",
      "F1 Score on the test set: 0.63\n",
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf247b2df469420fb4b7bb286d2dd7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on the test set: 0.68\n",
      "Precision on the test set: 0.68\n",
      "F1 Score on the test set: 0.68\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(resized_model, custom_test_loader)\n",
    "calculate_metrics(model, custom_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the model predicts best when the images have better quality, which makes sense: images are already resized when entering the model, which already oversimplifies some fire patterns. Doing so twice only makes it worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess it makes sense to check if dynamic resizing makes the algorithm better. Dynamic resizing, for this use case, is resizing to an aspect ratio of 3:2 for images in landscape (width > height) and 2:3 for images in portrait (width < height)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new Dataset class and train the regular model like before. This new Dataset class will not have a transformer input since the transformers.Resize() transformation will have a different input depending on the image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeFireDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform_resize : transforms.Resize= ...\n",
    "        self.transform_totensor = transforms.ToTensor()\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        # Store the folder names in a dictionary as the class names alongside the class numeric label\n",
    "        self.class_to_idx = {} \n",
    "        for i, cls in enumerate(self.classes):\n",
    "            self.class_to_idx[cls] = i\n",
    "\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        for class_name in self.classes: # Fetch the folders through the class name\n",
    "            class_path = os.path.join(self.root_dir, class_name)\n",
    "            for filename in os.listdir(class_path): # Fetch the images inside each folders\n",
    "                img_path = os.path.join(class_path, filename) # Obtain the name of the current image\n",
    "                data.append((img_path, self.class_to_idx[class_name])) # Add the image to a list paired with its class' numeric label\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx): # data[idx]\n",
    "        img_path, label = self.data[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_size = img.size\n",
    "        resize_dimensions = (384, 256) if img_size[0]> img_size[1] else (256, 384)\n",
    "\n",
    "        self.transform_resize = transforms.Resize(resize_dimensions)\n",
    "        img = self.transform_resize(img)\n",
    "        img = self.transform_totensor(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dynamic_resize_dummy_cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_resize_dataset = ResizeFireDataset(os.path.join(base_path, \"FIRE Dataset\"))\n",
    "\n",
    "dynamic_train_loader, dynamic_val_loader, dynamic_test_loader = split_dataset_into_dataloaders(dynamic_resize_dataset, 50, 0.7, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_resize_model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0003, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b5e5c727104dcaa3b11d434c1cfb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 384, 256] at entry 0 and [3, 256, 384] at entry 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\johnn\\Desktop\\Repos\\Capstonfire\\code_models\\dummy_cnn_experiments.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/johnn/Desktop/Repos/Capstonfire/code_models/dummy_cnn_experiments.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m train_model(dynamic_resize_model, criterion, optimizer, base_path, model_name, \u001b[39m20\u001b[39;49m, dynamic_train_loader, dynamic_val_loader)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\Desktop\\Repos\\Capstonfire\\code_models\\capstonfire_utils.py:117\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, base_path, model_name, num_epochs, train_loader, val_loader)\u001b[0m\n\u001b[0;32m    114\u001b[0m correct_train \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    115\u001b[0m total_train \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 117\u001b[0m \u001b[39mfor\u001b[39;49;00m i, data \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(train_loader, \u001b[39m0\u001b[39;49m):\n\u001b[0;32m    118\u001b[0m     inputs, labels \u001b[39m=\u001b[39;49m data\n\u001b[0;32m    119\u001b[0m     inputs, labels \u001b[39m=\u001b[39;49m inputs\u001b[39m.\u001b[39;49mto(device), labels\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;49;00m samples \u001b[39min\u001b[39;49;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\johnn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 384, 256] at entry 0 and [3, 256, 384] at entry 8"
     ]
    }
   ],
   "source": [
    "history = train_model(dynamic_resize_model, criterion, optimizer, base_path, model_name, 20, dynamic_train_loader, dynamic_val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh... \"RuntimeError: stack expects each tensor to be equal size, but got [3, 384, 256] at entry 0 and [3, 256, 384] at entry 28\". \n",
    "\n",
    "Guess dynamic resizing is out of the question. We could transform portrait images into landscape using transforms.Rotate, but fire images rotated 90ยบ are not exactly real life examples of fires and smokes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will throw this idea out and move to creating a binary classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model_name = \"binary_dummy_cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "binary_dataset = FireDataset(os.path.join(base_path, \"FIRE Dataset\"), binary_transforms)\n",
    "\n",
    "binary_train_loader, binary_val_loader, binary_test_loader = split_dataset_into_dataloaders(binary_dataset, 50, 0.7, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the output to one class\n",
    "class SimpleBinaryCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleBinaryCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5) # to capture basic patterns from the image\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)# to capture basic patterns from the previous patterns (results in capturing more complex patterns from the original image)\n",
    "        self.fc1 = nn.Linear(74420, 50) # 1000 = 20 * 50 * 1 -> conv2.output * batch_size * ?\n",
    "        self.fc2 = nn.Linear(50, 1) # DNN > WNN; also 1 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 74420)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = SimpleBinaryCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(binary_model.parameters(), lr=0.0003, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a binary classification, the training and testing loops need to be altered in the prediction part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # Ensure labels have the same size as the output\\n    labels_val = labels.view(-1, 1).float()\\n    loss_val = criterion(outputs_val, labels_val.float())\\n\\n    # Change here\\n    predicted_val = (torch.sigmoid(outputs_val) > 0.5).float()\\n    \\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Within the training loop\n",
    "\"\"\"\n",
    "    # Ensure labels have the same size as the output\n",
    "    labels_val = labels.view(-1, 1).float()\n",
    "    loss_val = criterion(outputs_val, labels_val.float())\n",
    "\n",
    "    # Change here\n",
    "    predicted_val = (torch.sigmoid(outputs_val) > 0.5).float()\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, hold on. So binary classification expects all data that enters the loop to be of the positive class. However, there are images that are not fire that look like fire, such as clouds. It would make more sense to maintain the training for a multi-class classification algorithm with two classes over just giving fire images to the dataset for training, so we can have more control over cases that look like fire but are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about it the tests we wanted to do. Let's now try to improve the model with more data (open \"improved_dummy_cnn.ipynb\" file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDIT: BCELoss also accepts images that are of the negative class. However, future improvements of this model would consider adding further labels, such as smoke and controlled fires. As such, maintaing the CrossEntropyLoss criterion allows for improved upscalling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
